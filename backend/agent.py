"""
Core agent loop: OpenAI function calling with iterative tool execution.
Yields structured steps for SSE streaming to the frontend.
"""

import json
import os
from typing import AsyncGenerator, Optional

from openai import AsyncOpenAI

from tools import FRIENDS_DB, TOOL_DEFINITIONS, TOOL_FUNCTIONS, set_user_location

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY", ""))

SYSTEM_PROMPT = """\
You are the **Group Dining Planner Agent** â€“ an expert at finding the perfect restaurant for a group of friends in the San Francisco Bay Area.

## User's Current Location
{user_location}

## Available Friends
{friends_list}

## Tools at Your Disposal
1. **get_friends_info** â€“ look up friends' locations & dining preferences
2. **search_restaurants** â€“ search Google Places for restaurants
3. **calculate_drive_times** â€“ get driving durations from friends to restaurants
4. **validate_restaurants** â€“ filter candidates by allergies, dislikes, blacklist, and max drive time
5. **rank_and_score** â€“ score and rank candidates using weighted criteria (drive time 40%, rating 35%, fairness 25%). Price is NOT a ranking factor â€” if a restaurant passes the budget filter, it should not be penalized or rewarded for being cheaper or more expensive.
6. **get_restaurant_details** â€“ fetch detailed info (reviews, phone, hours, website) from Google Places Details API
7. **book_ride** â€“ generate an Uber ride request link with prefilled pickup (user) & dropoff (restaurant)
8. **add_to_calendar** â€“ generate a Google Calendar link to schedule the dinner event
9. **get_yelp_info** â€“ fetch Yelp reviews, menu items with prices, and estimated per-person cost

## CRITICAL: You MUST think out loud between EVERY tool call

You are an agent that demonstrates visible reasoning. You MUST output text analysis between each tool call. NEVER call two tools back-to-back without analysis text in between.

## Your Process (follow strictly, with visible reasoning at every step)

### Step 1: Parse & Plan
Output a brief plan:
- Who's coming (including the user themselves!), cuisine, budget, occasion, constraints
- What you'll do and why

### Step 2: Look Up Friends
- Call **get_friends_info**
- THEN OUTPUT ANALYSIS: Review each person's preferences. Identify overlapping likes, conflicting dislikes, allergies that matter. Note the geographic spread **including the user's own location** and what area would be fairest.

### Step 3: Search Restaurants
- Calculate the geographic center of ALL people: the user ("Me") + all friends. The user's location is in the "User's Current Location" section above. Average all latitudes and all longitudes to get the center.
- Explain your search strategy (center point, radius, query, why)
- Call **search_restaurants** with this center point and an appropriate radius (start with 5000-8000m)
- THEN OUTPUT ANALYSIS: Review each candidate one by one:
  - Does it match the group's cuisine overlap?
  - Does the price level fit the budget?
  - Rating & review count â€” trustworthy or too few reviews?
  - Flag any that conflict with allergies/dislikes
  - Shortlist the top 5-6 most promising candidates for drive time check

### Step 4: Calculate Drive Times
- Explain: "I'll now check drive times for the shortlisted candidates"
- **CRITICAL**: Include the user ("Me") as an origin along with all friends. Use the user's lat/lng from the "User's Current Location" section. Add a "Me" entry to the origins list with the user's coordinates, alongside all the friends.
- Call **calculate_drive_times** (ONLY for the shortlisted candidates, not all)
- THEN OUTPUT ANALYSIS: Review the drive time results briefly before validation.

### Step 5: Validate & Filter
- Call **validate_restaurants** with the group's combined allergies, dislikes, blacklist, and max drive time constraint
- THEN OUTPUT ANALYSIS: Report which restaurants were removed and why. Count survivors.

**âš ï¸ CRITICAL: You MUST have at least 3 validated candidates before proceeding to Step 6 unless you have exhausted all relaxation retries. DO NOT call rank_and_score with fewer than 3 candidates.**

If fewer than 3 candidates survived validation, first ANALYZE the drive time data to understand WHY restaurants were rejected:
- Look at which specific person(s) had drive times exceeding the limit for the rejected restaurants.
- If most people are well within the limit but 1-2 people are over, note who they are and where they are located.
- This tells you which DIRECTION to shift the search center.

Then retry by going back to Step 3 (search). Relax constraints in this exact order (one per retry, max 3 retries):
  - **Retry 1 â€” Shift center toward the bottleneck person(s) + broaden radius**: Identify who exceeded the drive time limit most often. Shift the search center toward their location (e.g. average the current center with the bottleneck person's lat/lng). Also increase the radius (e.g. 5000 â†’ 10000m). This finds restaurants that are closer to the person who kept failing. Call **search_restaurants** with this adjusted center. Then re-run **calculate_drive_times** and **validate_restaurants** for the NEW results. Merge survivors with any previous survivors.
  - **Retry 2 â€” Broaden cuisine + shift center again**: Remove or loosen the cuisine filter (e.g. search for "restaurant" instead of a specific cuisine). If drive time is still the bottleneck, shift the center even further toward the bottleneck person, or try centering on a midpoint city/town between them and the rest of the group. Call **search_restaurants**, then **calculate_drive_times** and **validate_restaurants**. Merge survivors.
  - **Retry 3 â€” Broaden budget**: Expand the price range by Â±1 level. Call **search_restaurants**, then **calculate_drive_times** and **validate_restaurants**. Merge survivors.
  - **IMPORTANT**: Each retry MUST use different search parameters (center, radius, or query) than the previous search. If you pass the exact same lat/lng and radius, you will get the exact same results.
  - At each retry, EXPLICITLY STATE: "I only have N candidates but need at least 3. [Person X] exceeded the drive limit for most rejected restaurants. Shifting search center toward them: [new lat, lng] with radius [X]m."
  - After each retry, check the TOTAL survivor count (old + new). If >= 3, proceed to Step 6. Otherwise, try the next relaxation.
  - If still < 3 after all 3 retries, proceed with what you have â€” but NEVER stop at just 1 without trying.

### Step 6: Score & Rank
- Call **rank_and_score** with ALL validated candidates (from initial + any retries), drive times, budget level, and preferred cuisines
- THEN OUTPUT ANALYSIS: Review the scoring breakdown. Highlight the top 3 and explain why they scored highest.

### Step 7: Get Details for Top 3 (MANDATORY â€” DO NOT SKIP)
- You MUST call **get_restaurant_details** with the place_ids of the top 3 ranked restaurants. This is NOT optional â€” the frontend relies on this data to show phone numbers, websites, hours, and reviews in the recommendation cards.
- THEN OUTPUT ANALYSIS: Incorporate reviews, hours, and other details into your final assessment.

### Step 7b: Get Yelp Data for Top 3 (MANDATORY â€” DO NOT SKIP)
- You MUST call **get_yelp_info** with the top 3 restaurants (name, latitude, longitude). This is NOT optional â€” the frontend relies on this data to show Yelp ratings, popular dishes, and estimated costs in the recommendation cards.
- THEN OUTPUT ANALYSIS: Compare Yelp vs Google ratings. Note popular dishes found in Yelp reviews. Report menu items with prices if available, and the estimated per-person dinner cost.

### Step 8: Present Top 3
**âš ï¸ CRITICAL: Do NOT recap, review, or summarize previous steps. Do NOT say things like "After analyzingâ€¦", "Based on our searchâ€¦", "Let me review what we foundâ€¦". Jump DIRECTLY into presenting the three restaurants. The user has already seen your thinking â€” just give them the results.**

For each recommendation:
- Name, cuisine type, Google rating (â˜…) and Yelp rating (â˜…) side by side, price level ($$), address
- Drive time for EACH person (including "Me")
- Score breakdown (Drive Time / Rating / Fairness / Price / Total)
- Key reviews or highlights from both Google and Yelp
- Popular dishes mentioned across both review sources
- Menu items with prices if available from Yelp (show 3-5 highlight items)
- Estimated per-person dinner cost if available
- 1-2 sentences: why this restaurant is great for THIS specific group
- Any trade-offs to be aware of

## Important Rules
- **ALWAYS include the user ("Me") in drive time calculations and search center.** The user is dining too! Use their location from the "User's Current Location" section. If the user's location is "Not available", ask them for it.
- **ALWAYS call get_restaurant_details AND get_yelp_info for your top 3 before presenting final recommendations.** Never skip these â€” the frontend needs phone, website, hours, Yelp ratings, and popular dishes to render complete recommendation cards. If you skip them, the cards will appear broken/empty.
- ALWAYS output reasoning text before AND after each tool call. This is mandatory.
- Only call calculate_drive_times for your shortlisted candidates (5-6 max), not every single result.
- If the user is vague about a field, pick a sensible default and state it.
- Max 3 relaxation retries (radius â†’ cuisine â†’ budget). If still < 3 candidates after all retries, present what you have and explain.
- Respond in the SAME LANGUAGE as the user's message (Chinese â†’ Chinese, English â†’ English).
- Keep each thinking block concise (3-6 sentences), not walls of text.
- NEVER end without presenting your Top 3 final recommendations. Even if constraints can't be perfectly met, always give actionable picks with trade-off notes.
- When you present the final Top 3, that is your LAST message â€” do not say "stay tuned" or promise more analysis.
- ALWAYS include the phone number (from get_restaurant_details) in your final Top 3 recommendations. Format it clearly like: ðŸ“ž (650) 555-1234. The frontend will auto-render it as a clickable "Call to Reserve" button.
- When the user asks to reserve/book a table, call **get_restaurant_details** to get the phone number, then present it with the ðŸ“ž prefix so they can tap to call directly.
- When the user asks for dish recommendations, use BOTH Google reviews (from **get_restaurant_details**) AND Yelp reviews (from **get_yelp_info**) to find frequently mentioned dishes. Cross-reference with Yelp menu items and prices when available. Present dishes with prices if known.
- **Do NOT include Uber/ride links or calendar links in the Top 3 recommendations.** Only provide these when the user explicitly asks.
- When the user asks to book a ride, get an Uber, or go to a restaurant, you MUST call the **book_ride** tool to generate the link. NEVER fabricate or guess Uber URLs yourself â€” always use the tool. Present the tool's returned link using markdown: `[ðŸš— Book Uber to RESTAURANT_NAME](uber_link)`.
- When the user wants to schedule the dinner or add it to their calendar, call **add_to_calendar** and present the link using markdown: `[ðŸ“… Add to Calendar](calendar_link)`.
"""


PRESENTATION_SYSTEM_PROMPT = """\
You are presenting the Top 3 restaurant recommendations for a group dinner.

**RULES:**
- Jump DIRECTLY into presenting the restaurants. No preamble, no recap, no "After analyzingâ€¦".
- Respond in the SAME LANGUAGE as the user's original message.
- ALWAYS include the phone number with ðŸ“ž prefix.
- Do NOT include Uber/ride links or calendar links.

**For each of the Top 3:**
- Name, cuisine type, Google rating (â˜…) and Yelp rating (â˜…) side by side, price level ($$), address
- Drive time for EACH person (including "Me")
- Score breakdown (Drive Time / Rating / Fairness / Total)
- Key reviews or highlights from both Google and Yelp
- Popular dishes mentioned across both review sources
- Menu items with prices if available from Yelp (show 3-5 highlight items)
- Estimated per-person dinner cost if available
- 1-2 sentences: why this restaurant is great for THIS specific group
- Any trade-offs to be aware of
- Phone number: ðŸ“ž (xxx) xxx-xxxx
"""


def _build_presentation_context(messages: list[dict]) -> list[dict]:
    """Build a minimal message list containing only the data the LLM needs
    to write the final Top-3 presentation, cutting ~70-80% of tokens."""

    # --- Extract the original user request ---
    user_message = ""
    for msg in messages:
        if msg["role"] == "user":
            user_message = msg["content"]
            break

    # --- Map tool_call_ids â†’ tool names ---
    tc_id_to_name: dict[str, str] = {}
    for msg in messages:
        if msg.get("role") == "assistant" and msg.get("tool_calls"):
            for tc in msg["tool_calls"]:
                tc_id_to_name[tc["id"]] = tc["function"]["name"]

    # --- Collect results only from tools needed for presentation ---
    KEEP = {
        "get_friends_info",
        "calculate_drive_times",
        "rank_and_score",
        "get_restaurant_details",
        "get_yelp_info",
    }
    tool_results: dict[str, list[str]] = {t: [] for t in KEEP}

    for msg in messages:
        if msg.get("role") == "tool":
            tool_name = tc_id_to_name.get(msg.get("tool_call_id", ""), "")
            if tool_name in KEEP:
                tool_results[tool_name].append(msg["content"])

    # --- Assemble a compact data block ---
    data_parts: list[str] = []
    for name in [
        "get_friends_info",
        "rank_and_score",
        "calculate_drive_times",
        "get_restaurant_details",
        "get_yelp_info",
    ]:
        results = tool_results.get(name, [])
        if not results:
            continue
        if name == "calculate_drive_times":
            for i, r in enumerate(results, 1):
                data_parts.append(f"### {name} (call {i}):\n{r}")
        else:
            data_parts.append(f"### {name}:\n{results[-1]}")

    data_block = "\n\n".join(data_parts)

    return [
        {"role": "system", "content": PRESENTATION_SYSTEM_PROMPT},
        {
            "role": "user",
            "content": (
                f"Original request: {user_message}\n\n"
                f"Here is all the data collected for the top restaurants:\n\n"
                f"{data_block}\n\n"
                f"Present the Top 3 restaurant recommendations now."
            ),
        },
    ]


class AgentSession:
    """Holds the message history so callers can persist it across turns."""

    def __init__(self, messages: list[dict]):
        self.messages = messages


def build_new_session(user_message: str, user_location: dict = None) -> AgentSession:
    """Create a fresh session with system prompt + first user message."""
    friends_list = "\n".join(
        f"- {f['name']} ({f['location']['address']})" for f in FRIENDS_DB["friends"]
    )
    if user_location and user_location.get("lat"):
        loc_str = (
            f"Lat: {user_location['lat']}, Lng: {user_location['lng']}, "
            f"Address: {user_location.get('address', 'Unknown')}"
        )
    else:
        loc_str = "Not available"
    system = SYSTEM_PROMPT.format(friends_list=friends_list, user_location=loc_str)
    return AgentSession([
        {"role": "system", "content": system},
        {"role": "user", "content": user_message},
    ])


async def run_agent(
    user_message: str,
    session: Optional[AgentSession] = None,
    user_location: dict = None,
) -> AsyncGenerator[tuple[str, object], None]:
    """
    Run the agent loop with streaming.
    Yields (step_type, content) tuples:
      - ("text_delta", str)    â†’ streaming text chunk
      - ("thinking_done", "")  â†’ text was thinking (tool calls follow)
      - ("final_done", "")     â†’ text was final answer (no tool calls)
      - ("tool_call", dict)    â†’ tool invocation info
      - ("tool_result", dict)  â†’ tool return data
      - ("error", str)         â†’ error info
    """
    # Store user location at the tool level so tools auto-inject "Me"
    set_user_location(user_location)

    if session is None:
        session = build_new_session(user_message, user_location)
    else:
        # Remind the agent of user's location on every follow-up message
        if user_location and user_location.get("lat"):
            loc_note = (
                f"[User's current location: Lat {user_location['lat']}, "
                f"Lng {user_location['lng']}, Address: {user_location.get('address', 'Unknown')}]"
            )
            session.messages.append({"role": "system", "content": loc_note})
        session.messages.append({"role": "user", "content": user_message})

    yield ("_session_ref", session)

    messages = session.messages
    _ready_for_presentation = False

    max_iterations = 25
    for _ in range(max_iterations):
        # â”€â”€ Pick the right context for the LLM call â”€â”€
        if _ready_for_presentation:
            llm_messages = _build_presentation_context(messages)
            create_kwargs = {}
        else:
            llm_messages = messages
            create_kwargs = {"tools": TOOL_DEFINITIONS, "tool_choice": "auto"}

        # â”€â”€ Stream from OpenAI â”€â”€
        stream = await client.chat.completions.create(
            model="gpt-5-mini",
            messages=llm_messages,
            stream=True,
            **create_kwargs,
        )

        accumulated_content = ""
        # {index: {"id": str, "name": str, "arguments": str}}
        accumulated_tool_calls: dict[int, dict] = {}

        async for chunk in stream:
            delta = chunk.choices[0].delta

            # Stream text deltas
            if delta.content:
                accumulated_content += delta.content
                yield ("text_delta", delta.content)

            # Accumulate tool call deltas
            if delta.tool_calls:
                for tc_delta in delta.tool_calls:
                    idx = tc_delta.index
                    if idx not in accumulated_tool_calls:
                        accumulated_tool_calls[idx] = {
                            "id": "",
                            "name": "",
                            "arguments": "",
                        }
                    if tc_delta.id:
                        accumulated_tool_calls[idx]["id"] = tc_delta.id
                    if tc_delta.function:
                        if tc_delta.function.name:
                            accumulated_tool_calls[idx]["name"] = tc_delta.function.name
                        if tc_delta.function.arguments:
                            accumulated_tool_calls[idx]["arguments"] += tc_delta.function.arguments

        # â”€â”€ Stream finished â€” build assistant message for history â”€â”€
        tool_calls_list = [
            accumulated_tool_calls[i]
            for i in sorted(accumulated_tool_calls.keys())
        ]

        assistant_dict: dict = {"role": "assistant", "content": accumulated_content}
        if tool_calls_list:
            assistant_dict["tool_calls"] = [
                {
                    "id": tc["id"],
                    "type": "function",
                    "function": {
                        "name": tc["name"],
                        "arguments": tc["arguments"],
                    },
                }
                for tc in tool_calls_list
            ]
        messages.append(assistant_dict)

        # â”€â”€ No tool calls â†’ final answer â”€â”€
        if not tool_calls_list:
            yield ("final_done", "")
            return

        # â”€â”€ Had tool calls â†’ text was thinking â”€â”€
        yield ("thinking_done", "")

        # â”€â”€ Execute each tool call â”€â”€
        executed_tool_names: set[str] = set()
        for tc in tool_calls_list:
            fn_name = tc["name"]
            fn_args = json.loads(tc["arguments"])
            executed_tool_names.add(fn_name)

            yield ("tool_call", {"tool": fn_name, "args": fn_args})

            fn = TOOL_FUNCTIONS.get(fn_name)
            if fn is None:
                result = {"error": f"Unknown tool: {fn_name}"}
            else:
                try:
                    result = await fn(**fn_args)
                except Exception as exc:
                    result = {"error": f"Tool execution failed: {str(exc)}"}

            yield ("tool_result", {"tool": fn_name, "result": result})

            messages.append({
                "role": "tool",
                "tool_call_id": tc["id"],
                "content": json.dumps(result, ensure_ascii=False, default=str),
            })

        # â”€â”€ After get_yelp_info, switch to trimmed context for presentation â”€â”€
        if "get_yelp_info" in executed_tool_names:
            _ready_for_presentation = True

    yield ("error", "Agent reached maximum iterations without completing.")
